Number of Data Samples:  1288
Size of a data sample:  1850
Number of Class Labels:  7

Precision : 0.36735002603546363, Recall : 0.422491900533061, F-score : 0.37484550364306407

Best parameters for polynomial kernel :  SVC(C=1, gamma=0.1, kernel='poly')
Best parameters for rbf kernel :  SVC(C=10, gamma=0.01)

size of training Data is  966 and Testing Data is  322

Projecting the input data on the eigenfaces orthonormal basis
Sample Data point after applying PCA
 [-1.984066   -1.044305    2.1029456   0.05818834 -0.7666823  -0.5089284
  0.86435366  1.049901    0.4420051   0.006204   -0.04250183  0.6225575
  0.4693835   2.3511052   1.7237217   0.10915197 -2.2090898  -4.406188
  2.1202826  -1.128263    0.21517102 -0.31582078  1.122678   -0.32830057
  0.13496216  1.0731238   0.7420193  -0.0962928   3.0871415   0.8903242
 -0.87530065  1.1568066   1.3412193   1.6975158   1.2990061  -1.2808712
 -0.6352997  -2.293146   -0.00597286 -1.4680864  -0.4635903  -1.0018792
 -1.4110205   1.0017471   2.1345124  -1.9148775  -0.26174253 -0.9990802
  4.784047    3.2903636   1.9490876  -1.4247186  -0.3121616   1.9516314
 -1.1058837   0.36991975  1.1436087   0.8237482   0.86697763  0.5787389
 -0.4327175  -2.0293334   1.3002176   1.8583834   5.0937467  -0.7262809
  0.5821349  -0.84914786 -0.23110111 -2.1124325  -1.6454642  -0.19519222
 -1.7629724  -2.9430745  -2.1325085   0.4320142  -0.13252006  1.23767
  0.79725087 -1.3859146  -2.0111713  -2.7584949   1.4824637   0.21337837
  0.26503238 -0.15020366  1.172552    0.8152693   1.2804368   0.02700928
 -0.984895    0.3423536   1.0494697   0.7835241   0.5850636  -0.57339483
 -1.4312292  -0.9015413  -0.39235112  1.1335824   1.2190773  -1.232391
 -0.49647814  2.084458    0.7316276   1.512274   -1.8757625  -0.74686164
  1.4159186  -1.7895926   1.756278   -0.516549    1.3559086  -1.5792224
 -0.15670957  1.9034024  -1.938322    1.0696793  -1.1237036  -0.09334634
  0.10955261  1.9987429   1.0141165  -0.13221504  0.8153593   0.86632025
  0.9809934  -0.57027555  0.01025108  0.41289714  0.22995904 -1.5182807
 -1.0007333  -0.82116497  0.79797643 -0.48003396 -0.40796012 -0.31665087
  1.0505741   0.10680826 -0.4537525   0.60348076  1.8703227   0.29121658
  0.51682675 -1.4703196   1.2132099  -0.19904895 -0.59685695  0.5082295
 -1.5137206  -1.886842   -1.0714867   0.26429015 -0.55688304 -1.482604
 -0.25011656  0.12856615 -0.04889798  1.6091245   1.3799597  -2.4344275
 -0.06166458 -0.98554164 -0.13688561 -0.22726284  0.15841845 -0.36151803
  0.6645808   1.0679337   0.7588145   1.0556493   1.2874746  -0.6705826
 -1.4265447  -0.99957466 -1.3234      0.5389074  -1.7750211   0.7579484
 -0.17249936  0.601179   -0.00685884 -0.6561645   2.626278   -0.4025147
 -0.20463084 -0.91445124  1.0300593  -1.2139345  -0.9583692   1.1172043
  1.3004102  -1.0585374   0.59778124 -1.1550623   1.3066611   0.15022142
  0.5127144   0.6568609 ]
-----------------------------------------------------

Dimesnsions of training set = (966, 1850) and Test Set = (322, 1850)
Fitting the classifier to the training set
done in 37.064s

Best estimator found by grid search:
SVC(C=1000.0, class_weight='balanced', gamma=0.001)

Predicting people's names on the test set
Accuracy score:84.47%
                   precision    recall  f1-score   support

     Ariel Sharon       0.62      0.77      0.69        13
     Colin Powell       0.78      0.88      0.83        60
  Donald Rumsfeld       0.90      0.67      0.77        27
    George W Bush       0.91      0.92      0.91       146
Gerhard Schroeder       0.79      0.76      0.78        25
      Hugo Chavez       0.67      0.53      0.59        15
       Tony Blair       0.86      0.83      0.85        36

         accuracy                           0.84       322
        macro avg       0.79      0.77      0.77       322
     weighted avg       0.85      0.84      0.84       322

Confusion Matrix is:
[[ 10   1   1   1   0   0   0]
 [  2  53   1   3   0   1   0]
 [  3   3  18   2   0   1   0]
 [  1   6   0 134   2   1   2]
 [  0   2   0   2  19   1   1]
 [  0   2   0   2   1   8   2]
 [  0   1   0   3   2   0  30]]
